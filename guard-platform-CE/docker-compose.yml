##############################################################################
### To use this docker-compose file you have to
### initialise the following environment variables in file .env:
### (value are examples):
###
### RELEASE_DIR=guard-platform-v3.0
### ZOO_K_PORT=2181
### KAFKA_PORT_1=29092
### KAFKA_PORT_INT_1=9092
### KAFKA_PORT_TLS_1=39092
### KAFKA_PORT_SASL_1=49092
### KAFKA_PORT_2=29093
### KAFKA_PORT_INT_2=9093
### KAFKA_PORT_TLS_2=39093
### KAFKA_PORT_SASL_2=49093
### KAFKA_PORT_3=29094
### KAFKA_PORT_INT_3=9094
### KAFKA_PORT_TLS_3=39094
### KAFKA_PORT_SASL_3=49094
### VOLUME_DIR=/opt/guard
### GUARD_SERVER=example.server.com
### GUARD_SERVER_ADDRESS=10.0.0.7
### LS_PORT=5044
### ELASTIC_PORT_1=9200
### CB_MAN_PORT=5000
### DASHBOARD_PORT=83
### OPENVAS_PORT_1=9443
### BC_CONN_PORT=18080
### MONGODB_PORT=27017
### IDP_PORT=10443
###
#############################
### In ${VOLUME_DIR}/kafka-cluster-ssl/secrets must be present proper files 
### to allow TLS/SSL authentication.
###
###  WARNING: Algo1.1.2 must be recreate after kafka is online (and correct deployment.py)
###           logdata-anomaly-miner needs 2 cp commands TO-DO
##############################################################################
version: '3.6'
services:

  #  portainer:
  #    image: portainer/portainer-ce:latest
  #    ports:
  #      - "18000:8000"
  #      - "19000:9000"
  #    volumes:
  #    - /var/run/docker.sock:/var/run/docker.sock
  #    - /var/lib/docker/volumes:/var/lib/docker/volumes
  #    restart: always

  idp:
    image: guard/aaa/idm
    build:
      context: ${RELEASE_DIR}/aaa/identity_provider
      dockerfile: ./Dockerfile
    container_name: aa_module-idp
    ports:
      - ${IDP_PORT}:10443
    tty: true
    restart: unless-stopped

  zookeeper:
    image: zookeeper:3.7.0
    hostname: zookeeper
    ports:
      - "${ZOO_K_PORT}:${ZOO_K_PORT}"
    volumes:
      - ${VOLUME_DIR}/data/zookeeper/data:/data
      - ${VOLUME_DIR}/data/zookeeper/datalog:/datalog
    restart: unless-stopped

  kafka1:
    image: kafka_confluent:oauth
    build:
      context: ${RELEASE_DIR}/aaa/kafka_oauth
      dockerfile: ../kafka_confluent/Dockerfile
    hostname: kafka1
    ports:
      - "${KAFKA_PORT_1}:${KAFKA_PORT_1}"
      - "${KAFKA_PORT_INT_1}:${KAFKA_PORT_INT_1}"
      - "${KAFKA_PORT_TLS_1}:${KAFKA_PORT_TLS_1}"
      - "${KAFKA_PORT_SASL_1}:${KAFKA_PORT_SASL_1}"
    environment:
      KAFKA_SSL_CLIENT_AUTH: none
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://:${KAFKA_PORT_INT_1},EXTERNAL://${GUARD_SERVER}:${KAFKA_PORT_SASL_1},PLAIN_SSL://${GUARD_SERVER}:${KAFKA_PORT_TLS_1},PLAIN://${GUARD_SERVER}:${KAFKA_PORT_1}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:SASL_SSL,PLAIN_SSL:SSL,PLAIN:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:${ZOO_K_PORT}"
      KAFKA_BROKER_ID: 1
      KAFKA_OPTS: "-Djava.security.auth.login.config=/etc/kafka/secrets/kafka_server_jaas.conf"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      ##      KAFKA_OFFSETS_RETENTION_MINUTES: 3    
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_SSL_ENABLED_PROTOCOLS: TLSv1.3,TLSv1.2
      KAFKA_SECURITY_PROTOCOL: SASL_SSL
      KAFKA_SSL_KEYSTORE_FILENAME: kafka1.server.keystore.jks
      KAFKA_SSL_KEYSTORE_CREDENTIALS: kafka1_keystore_creds
      KAFKA_SSL_KEY_CREDENTIALS: kafka1_sslkey_creds
      KAFKA_SSL_TRUSTSTORE_FILENAME: kafka1.server.truststore.jks
      KAFKA_SSL_TRUSTSTORE_CREDENTIALS: kafka1_truststore_creds
      KAFKA_SASL_ENABLED_MECHANISMS: OAUTHBEARER
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: OAUTHBEARER
      KAFKA_LISTENER_NAME_INTERNAL_OAUTHBEARER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required;"
      KAFKA_LISTENER_NAME_INTERNAL_OAUTHBEARER_SASL_LOGIN_CALLBACK_HANDLER_CLASS: org.telematics.guard.aa.kafka.liboauthbearer.OAuthAuthenticateLoginCallbackHandler
      KAFKA_LISTENER_NAME_INTERNAL_OAUTHBEARER_SASL_SERVER_CALLBACK_HANDLER_CLASS: org.telematics.guard.aa.kafka.liboauthbearer.OAuthAuthenticateValidatorCallbackHandler
      KAFKA_LISTENER_NAME_EXTERNAL_OAUTHBEARER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required;"
      KAFKA_LISTENER_NAME_EXTERNAL_OAUTHBEARER_SASL_LOGIN_CALLBACK_HANDLER_CLASS: org.telematics.guard.aa.kafka.liboauthbearer.OAuthAuthenticateLoginCallbackHandler
      KAFKA_LISTENER_NAME_EXTERNAL_OAUTHBEARER_SASL_SERVER_CALLBACK_HANDLER_CLASS: org.telematics.guard.aa.kafka.liboauthbearer.OAuthAuthenticateValidatorCallbackHandler
      KAFKA_CONNECTIONS_MAX_REAUTH_MS: 60000
      KAFKA_AUTHORIZER_CLASS_NAME: org.telematics.guard.aa.kafka.liboauthbearer.CustomAuthorizer
      KAFKA_PRINCIPAL_BUILDER_CLASS: org.telematics.guard.aa.kafka.liboauthbearer.CustomPrincipalBuilder
      OAUTH_SERVER_BASE_URI: "https://idp:10443/oauth2/"
      OAUTH_SERVER_TOKEN_ENDPOINT_PATH: "/token"
      OAUTH_SERVER_INTROSPECTION_ENDPOINT_PATH: "/introspect"
      OAUTH_SERVER_CLIENT_ID: "kafka-broker"
      OAUTH_SERVER_CLIENT_SECRET: "yGC8KxKYYQ_q1UbTBAwxivThaZIa"
      OAUTH_SERVER_GRANT_TYPE: "client_credentials"
      OAUTH_SERVER_SCOPES: "kafka:cluster:kafka-cluster:cluster_action"
      OAUTH_SERVER_ACCEPT_UNSECURE_SERVER: "true"
      OAUTH_SERVER_ENFORCE: "false"
      # KAFKA_LOG4J_LOGGERS: "org.telematics=DEBUG"
      KAFKA_LOG4J_LOGGERS: "org.telematics=ERROR"
      ZOOKEEPER_SASL_ENABLED: "false"
    command: /etc/confluent/docker/dockerize -wait https://idp:10443 -skip-tls-verify -timeout 600s /etc/confluent/docker/run
    volumes:
      - ${VOLUME_DIR}/data/kafka1/data:/var/lib/kafka/data
      - ${VOLUME_DIR}/kafka-cluster-ssl/secrets:/etc/kafka/secrets
      - ${VOLUME_DIR}/kafka.jaas:/etc/kafka/secrets/kafka_server_jaas.conf
    depends_on:
      - zookeeper
      - idp
    restart: unless-stopped

  kafka2:
    image: kafka_confluent:oauth
    build:
      context: ${RELEASE_DIR}/aaa/kafka_oauth
      dockerfile: ../kafka_confluent/Dockerfile
    hostname: kafka2
    ports:
      - "${KAFKA_PORT_2}:${KAFKA_PORT_2}"
      - "${KAFKA_PORT_INT_2}:${KAFKA_PORT_INT_2}"
      - "${KAFKA_PORT_TLS_2}:${KAFKA_PORT_TLS_2}"
      - "${KAFKA_PORT_SASL_2}:${KAFKA_PORT_SASL_2}"
    environment:
      KAFKA_SSL_CLIENT_AUTH: none
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://:${KAFKA_PORT_INT_2},EXTERNAL://${GUARD_SERVER}:${KAFKA_PORT_SASL_2},PLAIN_SSL://${GUARD_SERVER}:${KAFKA_PORT_TLS_2},PLAIN://${GUARD_SERVER}:${KAFKA_PORT_2}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:SASL_SSL,PLAIN_SSL:SSL,PLAIN:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:${ZOO_K_PORT}"
      KAFKA_BROKER_ID: 2
      KAFKA_OPTS: "-Djava.security.auth.login.config=/etc/kafka/secrets/kafka_server_jaas.conf"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      ##      KAFKA_OFFSETS_RETENTION_MINUTES: 3    
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_SSL_ENABLED_PROTOCOLS: TLSv1.3,TLSv1.2
      KAFKA_SECURITY_PROTOCOL: SASL_SSL
      KAFKA_SSL_KEYSTORE_FILENAME: kafka2.server.keystore.jks
      KAFKA_SSL_KEYSTORE_CREDENTIALS: kafka2_keystore_creds
      KAFKA_SSL_KEY_CREDENTIALS: kafka2_sslkey_creds
      KAFKA_SSL_TRUSTSTORE_FILENAME: kafka2.server.truststore.jks
      KAFKA_SSL_TRUSTSTORE_CREDENTIALS: kafka2_truststore_creds
      KAFKA_SASL_ENABLED_MECHANISMS: OAUTHBEARER
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: OAUTHBEARER
      KAFKA_LISTENER_NAME_INTERNAL_OAUTHBEARER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required;"
      KAFKA_LISTENER_NAME_INTERNAL_OAUTHBEARER_SASL_LOGIN_CALLBACK_HANDLER_CLASS: org.telematics.guard.aa.kafka.liboauthbearer.OAuthAuthenticateLoginCallbackHandler
      KAFKA_LISTENER_NAME_INTERNAL_OAUTHBEARER_SASL_SERVER_CALLBACK_HANDLER_CLASS: org.telematics.guard.aa.kafka.liboauthbearer.OAuthAuthenticateValidatorCallbackHandler
      KAFKA_LISTENER_NAME_EXTERNAL_OAUTHBEARER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required;"
      KAFKA_LISTENER_NAME_EXTERNAL_OAUTHBEARER_SASL_LOGIN_CALLBACK_HANDLER_CLASS: org.telematics.guard.aa.kafka.liboauthbearer.OAuthAuthenticateLoginCallbackHandler
      KAFKA_LISTENER_NAME_EXTERNAL_OAUTHBEARER_SASL_SERVER_CALLBACK_HANDLER_CLASS: org.telematics.guard.aa.kafka.liboauthbearer.OAuthAuthenticateValidatorCallbackHandler
      KAFKA_CONNECTIONS_MAX_REAUTH_MS: 60000
      KAFKA_AUTHORIZER_CLASS_NAME: org.telematics.guard.aa.kafka.liboauthbearer.CustomAuthorizer
      KAFKA_PRINCIPAL_BUILDER_CLASS: org.telematics.guard.aa.kafka.liboauthbearer.CustomPrincipalBuilder
      OAUTH_SERVER_BASE_URI: "https://idp:10443/oauth2/"
      OAUTH_SERVER_TOKEN_ENDPOINT_PATH: "/token"
      OAUTH_SERVER_INTROSPECTION_ENDPOINT_PATH: "/introspect"
      OAUTH_SERVER_CLIENT_ID: "kafka-broker"
      OAUTH_SERVER_CLIENT_SECRET: "yGC8KxKYYQ_q1UbTBAwxivThaZIa"
      OAUTH_SERVER_GRANT_TYPE: "client_credentials"
      OAUTH_SERVER_SCOPES: "kafka:cluster:kafka-cluster:cluster_action"
      OAUTH_SERVER_ACCEPT_UNSECURE_SERVER: "true"
      OAUTH_SERVER_ENFORCE: "false"
      # KAFKA_LOG4J_LOGGERS: "org.telematics=DEBUG"
      KAFKA_LOG4J_LOGGERS: "org.telematics=ERROR"
      ZOOKEEPER_SASL_ENABLED: "false"
    command: /etc/confluent/docker/dockerize -wait https://idp:10443 -skip-tls-verify -timeout 600s /etc/confluent/docker/run
    volumes:
      - ${VOLUME_DIR}/data/kafka2/data:/var/lib/kafka/data
      - ${VOLUME_DIR}/kafka-cluster-ssl/secrets:/etc/kafka/secrets
      - ${VOLUME_DIR}/kafka.jaas:/etc/kafka/secrets/kafka_server_jaas.conf
    depends_on:
      - zookeeper
      - idp
    restart: unless-stopped

  kafka3:
    image: kafka_confluent:oauth
    build:
      context: ${RELEASE_DIR}/aaa/kafka_oauth
      dockerfile: ../kafka_confluent/Dockerfile
    hostname: kafka3
    ports:
      - "${KAFKA_PORT_3}:${KAFKA_PORT_3}"
      - "${KAFKA_PORT_INT_3}:${KAFKA_PORT_INT_3}"
      - "${KAFKA_PORT_TLS_3}:${KAFKA_PORT_TLS_3}"
      - "${KAFKA_PORT_SASL_3}:${KAFKA_PORT_SASL_3}"
    environment:
      KAFKA_SSL_CLIENT_AUTH: none
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://:${KAFKA_PORT_INT_3},EXTERNAL://${GUARD_SERVER}:${KAFKA_PORT_SASL_3},PLAIN_SSL://${GUARD_SERVER}:${KAFKA_PORT_TLS_3},PLAIN://${GUARD_SERVER}:${KAFKA_PORT_3}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:SASL_SSL,PLAIN_SSL:SSL,PLAIN:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:${ZOO_K_PORT}"
      KAFKA_BROKER_ID: 3
      KAFKA_OPTS: "-Djava.security.auth.login.config=/etc/kafka/secrets/kafka_server_jaas.conf"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      ##      KAFKA_OFFSETS_RETENTION_MINUTES: 3    
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_SSL_ENABLED_PROTOCOLS: TLSv1.3,TLSv1.2
      KAFKA_SECURITY_PROTOCOL: SASL_SSL
      KAFKA_SSL_KEYSTORE_FILENAME: kafka3.server.keystore.jks
      KAFKA_SSL_KEYSTORE_CREDENTIALS: kafka3_keystore_creds
      KAFKA_SSL_KEY_CREDENTIALS: kafka3_sslkey_creds
      KAFKA_SSL_TRUSTSTORE_FILENAME: kafka3.server.truststore.jks
      KAFKA_SSL_TRUSTSTORE_CREDENTIALS: kafka3_truststore_creds
      KAFKA_SASL_ENABLED_MECHANISMS: OAUTHBEARER
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: OAUTHBEARER
      KAFKA_LISTENER_NAME_INTERNAL_OAUTHBEARER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required;"
      KAFKA_LISTENER_NAME_INTERNAL_OAUTHBEARER_SASL_LOGIN_CALLBACK_HANDLER_CLASS: org.telematics.guard.aa.kafka.liboauthbearer.OAuthAuthenticateLoginCallbackHandler
      KAFKA_LISTENER_NAME_INTERNAL_OAUTHBEARER_SASL_SERVER_CALLBACK_HANDLER_CLASS: org.telematics.guard.aa.kafka.liboauthbearer.OAuthAuthenticateValidatorCallbackHandler
      KAFKA_LISTENER_NAME_EXTERNAL_OAUTHBEARER_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required;"
      KAFKA_LISTENER_NAME_EXTERNAL_OAUTHBEARER_SASL_LOGIN_CALLBACK_HANDLER_CLASS: org.telematics.guard.aa.kafka.liboauthbearer.OAuthAuthenticateLoginCallbackHandler
      KAFKA_LISTENER_NAME_EXTERNAL_OAUTHBEARER_SASL_SERVER_CALLBACK_HANDLER_CLASS: org.telematics.guard.aa.kafka.liboauthbearer.OAuthAuthenticateValidatorCallbackHandler
      KAFKA_CONNECTIONS_MAX_REAUTH_MS: 60000
      KAFKA_AUTHORIZER_CLASS_NAME: org.telematics.guard.aa.kafka.liboauthbearer.CustomAuthorizer
      KAFKA_PRINCIPAL_BUILDER_CLASS: org.telematics.guard.aa.kafka.liboauthbearer.CustomPrincipalBuilder
      OAUTH_SERVER_BASE_URI: "https://idp:10443/oauth2/"
      OAUTH_SERVER_TOKEN_ENDPOINT_PATH: "/token"
      OAUTH_SERVER_INTROSPECTION_ENDPOINT_PATH: "/introspect"
      OAUTH_SERVER_CLIENT_ID: "kafka-broker"
      OAUTH_SERVER_CLIENT_SECRET: "yGC8KxKYYQ_q1UbTBAwxivThaZIa"
      OAUTH_SERVER_GRANT_TYPE: "client_credentials"
      OAUTH_SERVER_SCOPES: "kafka:cluster:kafka-cluster:cluster_action"
      OAUTH_SERVER_ACCEPT_UNSECURE_SERVER: "true"
      OAUTH_SERVER_ENFORCE: "false"
      # KAFKA_LOG4J_LOGGERS: "org.telematics=DEBUG"
      KAFKA_LOG4J_LOGGERS: "org.telematics=ERROR"
      ZOOKEEPER_SASL_ENABLED: "false"
    command: /etc/confluent/docker/dockerize -wait https://idp:10443 -skip-tls-verify -timeout 600s /etc/confluent/docker/run
    volumes:
      - ${VOLUME_DIR}/data/kafka3/data:/var/lib/kafka/data
      - ${VOLUME_DIR}/kafka-cluster-ssl/secrets:/etc/kafka/secrets
      - ${VOLUME_DIR}/kafka.jaas:/etc/kafka/secrets/kafka_server_jaas.conf
    depends_on:
      - zookeeper
      - idp
    restart: unless-stopped

  ##kafdrop:
  ##  image: obsidiandynamics/kafdrop 
  ##  ports:
  ##    - "19100:9000"
  ## environment:
  ##     KAFKA_BROKERCONNECT: "kafka1:9092,kafka2:9093,kafka3:9094"
  ##   depends_on:
  ##    - kafka1
  ##      - kafka2
  ##      - kafka3
  ##    restart: unless-stopped

  logstash_guard:
    image: docker.elastic.co/logstash/logstash:${TAG:-7.11.0}
    container_name: logstash_guard
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
      SERVER_ADDRESS: "kafka1"
      ELASTIC_SERVER: "es01"
      KAFKA_PORT: ${KAFKA_PORT_1}
      ELASTIC_PORT: ${ELASTIC_PORT_1}
    volumes:
      - ~/${RELEASE_DIR}/centralized_svc/logstash-guard/config:/usr/share/logstash/config/
      - ~/${RELEASE_DIR}/centralized_svc/logstash-guard/pipeline:/usr/share/logstash/pipeline
      - ~/${VOLUME_DIR}/logstash-cb/file-output:/var/logstash-file-output
    expose:
      - "9001"
      - "${LS_PORT}"
      - "9600"
    ports:
      - "9001:9001"
      - "${LS_PORT}:${LS_PORT}"
      - "9600:9600"
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    restart: unless-stopped

  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.1
    container_name: es01
    environment:
      - node.name=es01
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es02,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ${VOLUME_DIR}/elastic/data01:/usr/share/elasticsearch/data
    ports:
      - "${ELASTIC_PORT_1}:${ELASTIC_PORT_1}"
    networks:
      - elastic
      - default
    restart: unless-stopped
  es02:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.1
    container_name: es02
    environment:
      - node.name=es02
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es01,es03
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ${VOLUME_DIR}/elastic/data02:/usr/share/elasticsearch/data
    networks:
      - elastic
      - default
    restart: unless-stopped
  es03:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.1
    container_name: es03
    environment:
      - node.name=es03
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=es01,es02
      - cluster.initial_master_nodes=es01,es02,es03
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ${VOLUME_DIR}/elastic/data03:/usr/share/elasticsearch/data
    networks:
      - elastic
      - default
    restart: unless-stopped

  kib01:
    image: docker.elastic.co/kibana/kibana:7.10.1
    container_name: kib01
    ports:
      - 5601:5601
    environment:
      ELASTICSEARCH_URL: http://es01:9200
      ELASTICSEARCH_HOSTS: '["http://es01:9200","http://es02:9200","http://es03:9200"]'
    networks:
      - elastic

  cb-manager:
    image: guardproject/cb-manager:master
    hostname: cb-manager
    container_name: cb-manager.master
    environment:
      - CB_MAN_ELASTICSEARCH_ENDPOINT=${GUARD_SERVER_ADDRESS}:${ELASTIC_PORT_1}
      - CB_MAN_AUTH=true
      - CB_MAN_HOST=0.0.0.0
      - CB_MAN_PORT=5000
      - CB_MAN_HTTPS=false
      - CB_MAN_AUTH_ENABLED=true
      - CB_MAN_AUTH_HEADER_PREFIX=GUARD
      - CB_MAN_AUTH_SECRET_KEY=guard-secret-key
      - CB_MAN_HEARTBEAT_TIMEOUT=10s
      - CB_MAN_HEARTBEAT_PERIOD=1min
      - CB_MAN_ELASTICSEARCH_ENDPOINT=localhost:9200
      - CB_MAN_ELASTICSEARCH_TIMEOUT=20s
      - CB_MAN_ELASTICSEARCH_RETRY_PERIOD=1min
      - CB_MAN_ELASTIC_APM_ENABLED=false
      - CB_MAN_ELASTIC_APM_SERVER=http://localhost:8200
      - CB_MAN_LOG_CONFIG=log.yaml
    network_mode: "host"
    expose:
      - "${CB_MAN_PORT}"
    restart: unless-stopped

  security-dashboard:
    image: security-dashboard:security-dashboard-guard
    build:
      context: ${RELEASE_DIR}/core_framework/security_dashboard/guard_docker
      args:
        uid: ${UID}
    container_name: security-dashboard
    environment:
      - APACHE_RUN_USER=#${UID}
      - APACHE_RUN_GROUP=#${UID}
    ports:
      - "${DASHBOARD_PORT}:80"
    networks:
      backend:
        aliases:
          - security-dashboard
    depends_on:
      - cb-manager
    restart: unless-stopped

  mysql-db:
    image: mysql:5.7
    container_name: mysql-db
    environment:
      - MYSQL_ROOT_PASSWORD=securerootpassword
      - MYSQL_DATABASE=security_dashboard
      - MYSQL_USER=sduser
      - MYSQL_PASSWORD=rootguard2021
    volumes:
      - ~/${RELEASE_DIR}/core_framework/security_dashboard/guard_docker/run/var:/var/lib/mysql
    ports:
      - "3307:3306"
    networks:
      backend:
        aliases:
          - db
    restart: unless-stopped

  algo5:
    container_name: algo5_container
    build: ${RELEASE_DIR}/core_framework/security_services/algo5
    volumes:
      - /opt/scan_reports:/opt/algo5/Vulnerability/reports
    tty: true
    stdin_open: false
    networks:
      - algo5_net

  openvas:
    image: mikesplain/openvas
    hostname: openvas
    ports:
      - "${OPENVAS_PORT}:443"
      - "9390:9390"
    expose:
      - "${OPENVAS_PORT}"
    environment:
      - PUBLIC_HOSTNAME=${GUARD_SERVER}
      - OV_PASSWORD=guard2020
    restart: unless-stopped

  # TO-DO: eventually correct IP address in deployment.py  
  algo1.1.2:
    container_name: algo1.1.2
    network_mode: "host"
    image: algo1.1.2:$TAG2
    build:
      context: ${RELEASE_DIR}/core_framework/security_services/algo1.1/algo1.1.2/version3
      dockerfile: Dockerfile
    environment:
      SERVER_ADDRESS: ${GUARD_SERVER_ADDRESS}
      KAFKA_PORT: ${KAFKA_PORT_INT_1}
    depends_on:
      - kafka1
      - kafka2
      - kafka3
    restart: unless-stopped

  algo1.2:
    container_name: algo1.2
    network_mode: "host"
    image: algo1.2:$TAG2
    ports:
      - "7000:7000"
    expose:
      - 7000
    build:
      context: ${RELEASE_DIR}/core_framework/security_services/algo1.2
      dockerfile: src/Dockerfile
    environment:
      KAFKA_BOOTSTRAP_SERVERS: guard3.westeurope.cloudapp.azure.com:49092
      KAFKA_CLIENT_ID: algo1.2
      KAFKA_SECURITY_PROTOCOL: SASL_SSL
      KAFKA_SSL_CAFILE: ./ssl/certs/truststore.pem
      KAFKA_SASL_MECHANISM: OAUTHBEARER
      OAUTH2_CLIENT_ID: XXOSSeamgNef3945snnxrAxKIt0a
      OAUTH2_SECRET: 5CsFBAp80bZamkEfeR5hJd7_HZca
      OAUTH2_TOKEN_URI: https://guard3.westeurope.cloudapp.azure.com:10443/oauth2/token
      OAUTH2_IDP_TLS: ./ssl/certs/truststore.pem
    restart: unless-stopped

  # Algo 4
  ## mongodb:
  ##   container_name: mongodb
  ##   image: mongo:3.6.8
  ##   ports: 
  ##        - "${MONGODB_PORT}:${MONGODB_PORT}"
  ##    expose: 
  ##        - ${MONGODB_PORT}
  ##    volumes: 
  ##        - ~/${RELEASE_DIR}/core_framework/security_services/algo4/blockchain-connector/mongo-volume:/data/db

  ## blockchain-connector:
  ##  image: blockchain-connector:blockchain-connector-guard
  ##  container_name: blockchain-connector
  ##  build: 
  ##       context: ~/${RELEASE_DIR}/core_framework/security_services/algo4/blockchain-connector
  ##  ports: 
  ##      - "${BC_CONN_PORT}:8080"
  ##  volumes:
  ##      - ~/${RELEASE_DIR}/core_framework/security_services/algo4/blockchain-connector:/app
  ##  depends_on:
  ##    - mongodb

  #  To Do: cp ~/guard-platform-v3.0/local_sidercars/log_data_agents/logdata-anomaly-miner/source/root/etc/aminer/template_config.yml ~/guard-platform-v3.0/local_sidercars/log_data_agents/logdata-anomaly-miner/source/root/etc/aminer/config.yml
  #         cp ~/guard-platform-v3.0/local_sidercars/log_data_agents/logdata-anomaly-miner/source/root/etc/aminer/conf-available/generic/ApacheAccessModel.py ~/guard-platform-v3.0/local_sidercars/log_data_agents/logdata-anomaly-miner/source/root/etc/aminer/conf-enabled/

  logdata-anomaly-miner:
    container_name: logdata-anomaly-miner
    network_mode: "host"
    image: aecid/logdata-anomaly-miner:latest
    build:
      context: ${RELEASE_DIR}/local_sidercars/log_data_agents/logdata-anomaly-miner
      dockerfile: Dockerfile
    volumes:
      - ~/${RELEASE_DIR}/local_sidercars/log_data_agents/logdata-anomaly-miner/source/root/etc/aminer/:/etc/aminer
    restart: unless-stopped

  smart-controller:
    container_name: smart-controller
    network_mode: "host"
    image: smart-controller:$TAG2
    build:
      context: ${RELEASE_DIR}/core_framework/security_controller/spring-boot-kafka-app
      dockerfile: Dockerfile
    ports:
      - 9000:9000
    depends_on:
      - cb-manager
      - kafka1
      - kafka2
      - kafka3
    restart: unless-stopped

volumes:
  mongo-volume:


networks:
  backend:
    name: backend-network
  elastic:
    driver: bridge
  algo5_net:


